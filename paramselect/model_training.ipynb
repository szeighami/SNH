{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Here we directly train an ExtraTreeRegressor directly\n",
    "# since automl module is not avialable publicly\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# import automl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>n</th>\n",
       "      <th>eps</th>\n",
       "      <th>best</th>\n",
       "      <th>neps</th>\n",
       "      <th>sqrtneps</th>\n",
       "      <th>hot10</th>\n",
       "      <th>entropy_512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gowalla_Cook</td>\n",
       "      <td>98218</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.01427</td>\n",
       "      <td>679</td>\n",
       "      <td>7.340522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gowalla_Cook</td>\n",
       "      <td>98218</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.01009</td>\n",
       "      <td>679</td>\n",
       "      <td>7.340522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           city      n   eps   best      neps  sqrtneps  hot10  entropy_512\n",
       "0  gowalla_Cook  98218  0.05  0.030  0.000204   0.01427    679     7.340522\n",
       "1  gowalla_Cook  98218  0.10  0.025  0.000102   0.01009    679     7.340522"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare dataset for training\n",
    "\n",
    "df = pd.read_csv(\"best_rho_GW_train_test.csv\", index_col=0)\n",
    "# create features\n",
    "df[\"neps\"] = 1/(df[\"n\"]*df[\"eps\"])\n",
    "df[\"sqrtneps\"] = (1/(df[\"n\"]*df[\"eps\"])).apply(np.sqrt)\n",
    "city_features = pd.read_csv(\"city_features_fromGW.csv\", index_col=0)\n",
    "data = df.join(city_features.set_index('city'), on=\"city\")\n",
    "\n",
    "# first 45 values are the train set, use rest as test\n",
    "data_train = data.iloc[:45,:]\n",
    "data_test = data.iloc[45:,:]\n",
    "print(len(data_train), len(data_test))\n",
    "data_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 45 45\n",
      "Testing set size 75\n",
      "       n   eps      neps  sqrtneps  entropy_512\n",
      "0  98218  0.05  0.000204   0.01427     7.340522\n",
      "1  98218  0.10  0.000102   0.01009     7.340522\n",
      "        n   eps      neps  sqrtneps  entropy_512\n",
      "45  54792  0.05  0.000365  0.019105     6.171421\n",
      "46  54792  0.10  0.000183  0.013510     6.171421\n"
     ]
    }
   ],
   "source": [
    "y_train = data_train['best']\n",
    "X_train = data_train.loc[:, data.columns != 'best']\n",
    "print('Training set size', len(y_train), len(X_train))\n",
    "\n",
    "X_test = data_test.loc[:, data.columns != 'best']\n",
    "print('Testing set size', len(X_test))\n",
    "\n",
    "# keep only the required features in the train set\n",
    "feature_set = ['n','eps','neps','sqrtneps', 'entropy_512']\n",
    "X_train = X_train[X_train.columns.intersection(feature_set)]\n",
    "X_test = X_test[X_test.columns.intersection(feature_set)]\n",
    "\n",
    "\n",
    "print(X_train.head(2))\n",
    "print(X_test.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -0.00353 (0.00161)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor(max_features=0.777777778, min_samples_leaf=0.000625,\n",
       "                    min_samples_split=0.00125, n_estimators=250)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the model with hyperparameter determine via automl\n",
    "model = ExtraTreesRegressor(n_estimators=250, max_features= 0.777777778, min_samples_leaf= 0.000625, min_samples_split= 0.00125)\n",
    "# Create cross-validation folds\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=7)\n",
    "# Evaluate mae by cross-validation\n",
    "n_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report approximate model performance\n",
    "print('MAE: %.5f (%.5f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model for later use\n",
    "import gzip\n",
    "import pickle\n",
    "with gzip.open('ParamSelect_trained_model.pklz', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>eps</th>\n",
       "      <th>neps</th>\n",
       "      <th>sqrtneps</th>\n",
       "      <th>entropy_512</th>\n",
       "      <th>predicted_vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>54792</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.019105</td>\n",
       "      <td>6.171421</td>\n",
       "      <td>0.030700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>54792</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.013510</td>\n",
       "      <td>6.171421</td>\n",
       "      <td>0.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>54792</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.009553</td>\n",
       "      <td>6.171421</td>\n",
       "      <td>0.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>54792</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.006755</td>\n",
       "      <td>6.171421</td>\n",
       "      <td>0.020400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>54792</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.004776</td>\n",
       "      <td>6.171421</td>\n",
       "      <td>0.016404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n   eps      neps  sqrtneps  entropy_512  predicted_vals\n",
       "45  54792  0.05  0.000365  0.019105     6.171421        0.030700\n",
       "46  54792  0.10  0.000183  0.013510     6.171421        0.025040\n",
       "47  54792  0.20  0.000091  0.009553     6.171421        0.022500\n",
       "48  54792  0.40  0.000046  0.006755     6.171421        0.020400\n",
       "49  54792  0.80  0.000023  0.004776     6.171421        0.016404"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to load model and make new predictions\n",
    "import gzip\n",
    "import pickle\n",
    "with gzip.open('ParamSelect_trained_model.pklz', 'r') as f:\n",
    "    est1 = pickle.load(f)\n",
    "y_pred = est1.predict(X_test)\n",
    "X_test_print = X_test.copy()\n",
    "X_test_print['predicted_vals'] = y_pred\n",
    "X_test_print.head(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# if we want predictions on the test set for which we already know good values of rho\n",
    "data_test_withvals =  data_test.dropna()\n",
    "X_test_withvals = data_test_withvals.loc[:, data_test_withvals.columns != 'best']\n",
    "y_test_withvals = data_test_withvals['best']\n",
    "X_test_withvals = X_test_withvals[X_test_withvals.columns.intersection(feature_set)]\n",
    "print('Records in test set with known best rho', len(X_test_withvals), len(y_test_withvals))\n",
    "\n",
    "y_pred = model.predict(X_test_withvals)\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "score_mse = mean_squared_error(y_test_withvals, y_pred)\n",
    "score_mae = mean_absolute_error(y_test_withvals, y_pred)\n",
    "score_re = mean_absolute_percentage_error(y_test_withvals,y_pred)\n",
    "print(score_mse, score_mae, score_re)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
